{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YUlcK7X8ONgn"
      ],
      "authorship_tag": "ABX9TyPJdnuzL2tTKmhzXm6aPAQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usseif97/MRNET-for-Knee-Diagnosis/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxH7h9zeclKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU not found')\n",
        "  raise SystemError('GPU device not found')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBOnK_3Scr9r",
        "colab_type": "code",
        "outputId": "ba9de0c6-d7a1-4a3b-b961-4bb4c295a665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# importing the drive to get data files\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS_7pcUfdkFA",
        "colab_type": "code",
        "outputId": "4a19f516-f5f7-4727-af67-74726e812e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-somF5HX8pG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append('/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6O5TAVx2KIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications, layers, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "import keras.backend.tensorflow_backend as tfback\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "root_path = '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0'\n",
        "tf.keras.backend.set_floatx('float64')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJMfIv9Hpk09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"tf.version is\", tf.version)\n",
        "#print(\"tf.keras.version is:\", keras.version)\n",
        "\n",
        "def _get_available_gpus():\n",
        "  \"\"\"Get a list of available gpu devices (formatted as strings).\n",
        "  # Returns\n",
        "     A list of available GPU devices. \n",
        "  \"\"\"\n",
        "#global _LOCAL_DEVICES\n",
        "  if tfback._LOCAL_DEVICES is None:\n",
        "    devices = tf.config.list_logical_devices()\n",
        "    tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "  return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "\n",
        "tfback._get_available_gpus = _get_available_gpus\n",
        "keras.backend.set_image_data_format('channels_first')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3pxhLd9QPqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%run datagen.ipynb\n",
        "%run model.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lo4ZmhI0aB_",
        "colab_type": "code",
        "outputId": "bc469f1c-837c-46bc-abfc-3dfba1481be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "start = timer()\n",
        "end = timer()\n",
        "print(end - start) # Time in seconds, e.g. 5.38091952400282"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2947999948664801e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZoUFu7rI7s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MRNetDataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, root_path = None, task = 'train', view = 'axial', result_label = 'abnormal', batch_size=1, shape=(256,256), n_channels=3,\n",
        "                 shuffle=False, extractor = None):\n",
        "    'Initialization'\n",
        "    self.root_path = '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0'\n",
        "    self.shape = shape\n",
        "    self.batch_size = batch_size\n",
        "    self.n_channels = n_channels\n",
        "    self.shuffle = shuffle\n",
        "    self.extractor = extractor\n",
        "    self.task = task\n",
        "    self.view = view\n",
        "    if self.task != 'train':\n",
        "      self.shuffle = False\n",
        "    self.result_label = result_label\n",
        "    records = pd.read_csv(self.root_path + f\"/{self.task}-{self.result_label}.csv\", header=None, names=['id', 'label'])\n",
        "    self.Y = records['label'].to_numpy()\n",
        "    if (self.task == 'train'):\n",
        "      self.num_examples = 1130\n",
        "    else:\n",
        "      self.num_examples = 120\n",
        "    \n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    'Updates indexes after each epoch'\n",
        "    if (self.task == 'train'):\n",
        "      self.indexes = np.arange(0, 1130)\n",
        "    else:\n",
        "      self.indexes = np.arange(1130, 1250)\n",
        "  \n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __load_scan(self, index):\n",
        "    index_extended = '0' * (4 - len(str(index))) + str(index)\n",
        "    path = self.root_path + f\"/{self.task}/{self.view}/{index_extended}.npy\"\n",
        "    print(f'loading example: {index}')\n",
        "    x = np.load(path)\n",
        "    x = np.stack((x,)*self.n_channels, axis=1)\n",
        "    return x\n",
        "\n",
        "  def __load_features(self, index):\n",
        "    index_extended = '0' * (4 - len(str(index))) + str(index)\n",
        "    path = self.root_path + f\"/{self.task}/{self.view}/{self.extractor}/{index_extended}.npy\"\n",
        "    x = np.load(path).reshape((1, 512))\n",
        "    return x\n",
        "\n",
        "  def __load_labels(self):\n",
        "    records = pd.read_csv(self.root_path + f\"/{self.task}-{self.result_label}.csv\", header=None, names=['id', 'label'])\n",
        "    self.Y = records['label'].to_numpy()\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    'Generate one batch of data'\n",
        "    X = np.empty((self.batch_size, self.n_channels))\n",
        "    if self.extractor == None:\n",
        "      X = np.empty((self.batch_size, self.n_channels, *self.shape))\n",
        "    else:\n",
        "      X = np.empty((self.batch_size, self.shape))\n",
        "      #X = tf.squeeze(X)\n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    for i, ind in enumerate(indexes):\n",
        "      #indexes[i] = '0' * (4 - len(str(num))) + str(num)\n",
        "      if self.extractor == None:\n",
        "        #X[i,] = self.__load_scan(ind)\n",
        "        X = self.__load_scan(ind)\n",
        "        #X = applications.vgg16.preprocess_input(X)\n",
        "        X = tf.expand_dims(X, 0)\n",
        "        \n",
        "      else:\n",
        "        X[i,] = self.__load_features(ind)\n",
        "\n",
        "    Y = self.Y[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the number of batches per epoch'\n",
        "    return int(np.floor(len(self.indexes) / self.batch_size))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrMTShT4hEkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run Once\n",
        "#Extracting Features with vgg16-transfer-learning to axial (Generator Mode)\n",
        "\n",
        "extract_axial_vgg = VggModel(root_path,'axial', 'abnormal', task='train')\n",
        "extract_axial_vgg.vgg_extractor.summary()\n",
        "start = timer()\n",
        "extract_axial_vgg.extract_features('train', save = True)\n",
        "end = timer()\n",
        "print(f'EXTRACTING AXIAL with VGG16 FINISHED in {end - start}s') #2411s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSSI94RBiSqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run Once\n",
        "#Extracting Features with vgg16-transfer-learning to coronal (Memory Mode)\n",
        "\n",
        "start = timer()\n",
        "X = load_view('train', 'coronal',0, 1130) #dict\n",
        "extract_coronal_vgg = VggModel(root_path,'coronal', 'abnormal', task='train')\n",
        "extract_coronal_vgg.vgg_extractor.summary()\n",
        "extract_coronal_vgg.extract_features('train', save = True, X = X)\n",
        "end = timer()\n",
        "print(f'EXTRACTING CORONAL with VGG16 FINISHED in {end - start}s -- (Memory Mode')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeaVdAwR1WPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run Once\n",
        "#Extracting Features with vgg16-transfer-learning to sagittal (Generator Mode with multi-processing workers = 6)\n",
        "\n",
        "start = timer()\n",
        "extract_sagittal_vgg = VggModel(root_path,'sagittal', 'abnormal', task='train')\n",
        "extract_sagittal_vgg.vgg_extractor.summary()\n",
        "extract_sagittal_vgg.extract_features('train', save = True)\n",
        "end = timer()\n",
        "print(f'EXTRACTING SAGITTAL with VGG16 FINISHED in {end - start}s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SruVMlxPl4ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train FC Layer with vgg16-transfer-learning to axial\n",
        "\n",
        "train_fc_axial_vgg = VggModel(root_path,'axial', 'abnormal', task='train')\n",
        "train_fc_axial_vgg.vgg_fc.summary()\n",
        "start = timer()\n",
        "history = train_fc_axial_vgg.train_fc(save_fc = True, memory = True)\n",
        "end = timer()\n",
        "print(f'TRAINING FC LAYER - AXIAL with VGG16 FINISHED in {end - start}s') #62s #692"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XwwAu45AdJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train FC Layer with vgg16-transfer-learning to coronal\n",
        "\n",
        "train_fc_coronal_vgg = VggModel(root_path,'coronal', 'abnormal', task='train')\n",
        "train_fc_coronal_vgg.vgg_fc.summary()\n",
        "start = timer()\n",
        "history = train_fc_coronal_vgg.train_fc(save_fc = True, memory = True)\n",
        "#end = timer()\n",
        "#print(f'TRAINING FC LAYER - CORONAL with VGG16 FINISHED in {end - start}s') #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAo6xBNlCxpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train FC Layer with vgg16-transfer-learning to sagittal\n",
        "\n",
        "train_fc_sagittal_vgg = VggModel(root_path,'sagittal', 'abnormal', task='train')\n",
        "train_fc_sagittal_vgg.vgg_fc.summary()\n",
        "start = timer()\n",
        "history = train_fc_sagittal_vgg.train_fc(save_fc = True, memory = True)\n",
        "#end = timer()\n",
        "#print(f'TRAINING FC LAYER - CORONAL with VGG16 FINISHED in {end - start}s') #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSOGnb1xEmfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "axial_predict = VggModel(root_path,'axial', 'abnormal', task='train')\n",
        "axial_predict.vgg_fc.summary()\n",
        "start = timer()\n",
        "axial_predictions = axial_predict.predict_fc()\n",
        "end = timer()\n",
        "print(f'PREDICTING FC LAYER - AXIAL with VGG16 FINISHED in {end - start}s')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukla49YWH8yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coronal_predict = VggModel(root_path,'coronal', 'abnormal', task='train')\n",
        "coronal_predict.vgg_fc.summary()\n",
        "start = timer()\n",
        "coronal_predictions = coronal_predict.predict_fc()\n",
        "end = timer()\n",
        "print(f'PREDICTING FC LAYER - CORONAL with VGG16 FINISHED in {end - start}s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDMGl_QVK9Ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sagittal_predict = VggModel(root_path,'sagittal', 'abnormal', task='train')\n",
        "sagittal_predict.vgg_fc.summary()\n",
        "start = timer()\n",
        "sagittal_predictions = sagittal_predict.predict_fc()\n",
        "end = timer()\n",
        "print(f'PREDICTING FC LAYER - SAGITTAL with VGG16 FINISHED in {end - start}s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIJ-IPB1LMhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Xp = np.concatenate((axial_predictions, coronal_predictions, sagittal_predictions), axis=1) #this is the input to sigmoid function\n",
        "\n",
        "inputs = keras.Input((3,))\n",
        "outputs = keras.layers.Dense(1, activation='sigmoid')(inputs)\n",
        "classifier_model = keras.Model(inputs, outputs)\n",
        "classifier_model.compile(\n",
        "  optimizer=keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy']\n",
        "  )\n",
        "classifier_model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUlcK7X8ONgn",
        "colab_type": "text"
      },
      "source": [
        "## **The next is rubbish:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoR2uT8RLAeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_features(root_dir = '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0', set = 'train', view = 'axial', model = 'VGG16'):\n",
        "  X = np.empty((0, 512))\n",
        "  start = 0\n",
        "  end = 10 ######\n",
        "  if set == 'train':\n",
        "    pass\n",
        "  else:\n",
        "    start = 1130\n",
        "    end = 1250\n",
        "  for i in range(start, end):\n",
        "    index = '0' * (4 - len(str(i))) + str(i)\n",
        "    path = root_dir + f\"/{set}/{view}/{model}/{index}.npy\"\n",
        "    print('loading', index)\n",
        "    x = np.load(path).reshape((1, 512))\n",
        "    X = np.concatenate((X, x), axis = 0)\n",
        "\n",
        "  return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEtXyEzlJUl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_labels(root_dir = '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0', set = 'train', case = 'abnormal'):\n",
        "  records = pd.read_csv(root_dir + f\"/train-{case}.csv\", header=None, names=['id', 'label'])\n",
        "  return records['label'].to_numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k45ZvkRZt7Xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_input():\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LJSrH-_jn9c",
        "colab_type": "code",
        "outputId": "d8eb57e6-eed8-4be1-9cfe-b773e0ee13e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = {}\n",
        "for i in range(1):\n",
        "  X[i] = load_scan(view='axial', num = i)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading 0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXL_VY-KyGDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_example(root_dir, view, num, features, model, set):\n",
        "  root_dir = '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0'\n",
        "  index = '0' * (4 - len(str(num))) + str(num)\n",
        "  np.save(open(f\"{root_dir}/{set}/{view}/{model}/{index}.npy\", 'wb'), features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYgsT_XI6vYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWZO1I3fncAw",
        "colab_type": "code",
        "outputId": "891bccbf-ac47-42ce-fd86-b151d0b2b237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "features = {}\n",
        "for i in range(1):\n",
        "  print(i)\n",
        "  x = X[i]\n",
        "  x = applications.vgg16.preprocess_input(x)\n",
        "  features[i] = vgg_fx.predict(\n",
        "      x, batch_size=tf.constant(x.shape[0]), verbose=0,\n",
        "  )\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfRri6DJ5qJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for example_num, example_features in features.items():\n",
        "  print('saving', example_num)\n",
        "  save_example('', 'axial', example_num, example_features, 'VGG16', 'train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LTggPB97NL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classifier\n",
        "#inputs = keras.Input(shape=(512))\n",
        "#outputs = layers.Dense(1, activation='relu')(inputs, training=False)\n",
        "#vgg_fc = keras.Model(inputs, outputs)\n",
        "#vgg_fc.summary()\n",
        "#vgg_fx.compile()\n",
        "vgg_fc = Sequential()\n",
        "vgg_fc.add(Input(shape = (512,)))\n",
        "vgg_fc.add(layers.Dense(1, activation='relu'))\n",
        "vgg_fc.summary()\n",
        "vgg_fc.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=20,\n",
        "                              verbose=0, mode='auto',\n",
        "                              restore_best_weights=True)\n",
        "\n",
        "Y_train = load_labels(case='abnormal')\n",
        "\n",
        "X_train = load_features()\n",
        "vgg_fc.fit(\n",
        "    x=X_train, y=Y_train[:50], batch_size=1, epochs=10, verbose=2, callbacks=[early_stopping],\n",
        "    validation_split=0.0, validation_data=None, shuffle=True,\n",
        ")\n",
        "\n",
        "\n",
        "#callbacks=[early_stopping],"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOmi6hSCe198",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train with custom data generator\n",
        "\n",
        "vgg_fc = Sequential()\n",
        "vgg_fc.add(Input(shape = (512,)))\n",
        "vgg_fc.add(layers.Dense(1, activation='relu'))\n",
        "vgg_fc.summary()\n",
        "vgg_fc.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                              min_delta=0,\n",
        "                              patience=20,\n",
        "                              verbose=0, mode='auto',\n",
        "                              restore_best_weights=True)\n",
        "\n",
        "params = {'shape': (512),\n",
        "          'batch_size': 1,\n",
        "          'shuffle': False,\n",
        "          'extractor': 'VGG16'}\n",
        "\n",
        "training_generator = MRNetDataGenerator(**params)\n",
        "\n",
        "vgg_fc.fit(\n",
        "    training_generator, epochs=50, verbose=2, callbacks=[early_stopping],\n",
        "    use_multiprocessing = False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4fFDbKeO-sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0'\n",
        "vgg_fc.save(root_dir + '/vgg16-fc-abnormal.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sXPamGqNll6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classifier\n",
        "vgg_full = Sequential()\n",
        "vgg_full.add(vgg_fx)\n",
        "vgg_full.add(vgg_fc)\n",
        "vgg_full.summary()\n",
        "vgg_full.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-hHfmPnUulD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape=(256,256,3))\n",
        "x = vgg_fx(inputs\n",
        "outputs = vgg_fc(x)\n",
        "vgg_full = keras.Model(inputs, outputs)\n",
        "vgg_full.summary()\n",
        "vgg_full.compile()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEZlqyK2MCJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = {}\n",
        "for i in range(1130, 1250):\n",
        "  X[i] = load_scan(set = 'valid', view='axial', num = i)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsLgE_NiOlge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = {}\n",
        "for i in range(1130, 1250):\n",
        "  print(i)\n",
        "  x = X[i]\n",
        "  applications.vgg16.preprocess_input(x)\n",
        "  features[i] = vgg_fx.predict(\n",
        "      x, batch_size=tf.constant(x.shape[0]), verbose=0,\n",
        "  )\n",
        "for example_num, example_features in features.items():\n",
        "  print('saving', example_num)\n",
        "  save_example('', 'axial', example_num, example_features, 'VGG16', 'valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqMHEIiVOsXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_valid = load_labels(case='abnormal', set = 'valid')\n",
        "\n",
        "X_valid = load_features(set='valid')\n",
        "vgg_fc.evaluate(\n",
        "    x=X_train, y=Y_train, batch_size=1, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPOCDtBIRtOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape=(None,256, 256, 3))\n",
        "x = layers.Flatten()(inputs)\n",
        "mo = keras.Model(inputs, x)\n",
        "mo.summary()\n",
        "mo.compile()\n",
        "\n",
        "arrr = np.random.rand(1, 10,256,256,3)\n",
        "\n",
        "moo = mo(arrr)\n",
        "moo.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJupd2uy_zM7",
        "colab_type": "code",
        "outputId": "b568d07c-0ea4-477a-ced0-76b8f4a9fdc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "tei = keras.Input(shape=(3, 256,256))\n",
        "te = applications.vgg16.preprocess_input(tei)\n",
        "moo = keras.Model(tei,te)\n",
        "moo.summary()\n",
        "moo.compile()\n",
        "inn = np.ones((2,3,256,256))\n",
        "\n",
        "for j, i in enumerate(inn):\n",
        "  print(i.shape, j)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_73\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_109 (InputLayer)       [(None, 3, 256, 256)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_13 [(None, 3, 256, 256)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_BiasAdd_13 (Tens [(None, 3, 256, 256)]     0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(3, 256, 256) 0\n",
            "(3, 256, 256) 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRxp-8huel4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iacnK5V3HKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_scan(task, view, index, root_path = root_path):\n",
        "    index_extended = '0' * (4 - len(str(index))) + str(index)\n",
        "    path = root_path + f\"/{task}/{view}/{index_extended}.npy\"\n",
        "    print(f'loading example: {index}')\n",
        "    x = np.load(path)\n",
        "    x = np.stack((x,)*3, axis=1)\n",
        "    return x\n",
        "\n",
        "def load_view(task, view, start, end, root_path = root_path):\n",
        "  data_size = end - start\n",
        "  X = {}\n",
        "  for i, index in enumerate(range(start, end)):\n",
        "    X[i] = load_scan(task, view, index, root_path)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3pKhXWqoaxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def save_example2(num, features, model):\n",
        "    index = '0' * (4 - len(str(num))) + str(num)\n",
        "    np.save(open(f\"{root_path}/{model.task}/{model.view}/VGG16/{index}.npy\", 'wb'), features)\n",
        "\n",
        "for example_num, example_features in model.features.items():\n",
        "  print('saving', example_num)\n",
        "  save_example2(example_num, example_features, model)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}