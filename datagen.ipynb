{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datagen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZn7aHUL+AkH/P4uFDBoHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usseif97/MRNET-for-Knee-Diagnosis/blob/master/datagen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqq7HVnakzgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y94wUg6kzRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnu55LjFxAxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc3zLCHWwyog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_scan(root_path, task, view, index):\n",
        "    index_extended = '0' * (4 - len(str(index))) + str(index)\n",
        "    path = root_path + f\"/{task}/{view}/{index_extended}.npy\"\n",
        "    print(f'loading example: {index}')\n",
        "    x = np.load(path)\n",
        "    x = np.stack((x,)*3, axis=3)\n",
        "    return x\n",
        "\n",
        "def load_view(root_path, task, view, start, end):\n",
        "  data_size = end - start\n",
        "  X = {}\n",
        "  for i, index in enumerate(range(start, end)):\n",
        "    X[i] = load_scan(root_path, task, view, index)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LuCZLDZbP7WT",
        "colab": {}
      },
      "source": [
        "class MRNetDataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, root_path = None, task = 'train', view = 'axial', result_label = 'abnormal', batch_size=1, shape=(256,256), n_channels=3,\n",
        "                 shuffle=False, extractor = None, bounds = None, X = None):\n",
        "    'Initialization'\n",
        "    self.root_path = '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0'\n",
        "    self.shape = shape\n",
        "    self.batch_size = batch_size\n",
        "    self.n_channels = n_channels\n",
        "    self.shuffle = shuffle\n",
        "    self.extractor = extractor\n",
        "    self.task = task\n",
        "    self.view = view\n",
        "    self.bounds = bounds\n",
        "    self.X = X\n",
        "    if self.task != 'train':\n",
        "      self.shuffle = False\n",
        "    self.result_label = result_label\n",
        "    records = pd.read_csv(self.root_path + f\"/{self.task}-{self.result_label}.csv\", header=None, names=['id', 'label'])\n",
        "    self.Y = records['label'].to_numpy()\n",
        "    if (self.task == 'train'):\n",
        "      if self.bounds == None:\n",
        "        self.num_examples = 1130\n",
        "      else:\n",
        "        self.num_examples = bounds[1] - bounds[0]\n",
        "    else:\n",
        "      self.num_examples = 120\n",
        "    \n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    'Updates indexes after each epoch'\n",
        "    if self.task == 'train':\n",
        "      if self.bounds != None:\n",
        "        self.indexes = np.arange(self.bounds[0], self.bounds[1])\n",
        "      else:\n",
        "        self.indexes = np.arange(0, 1130)\n",
        "    else:\n",
        "      self.indexes = np.arange(1130, 1250)\n",
        "  \n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __load_scan(self, index):\n",
        "    index_extended = '0' * (4 - len(str(index))) + str(index)\n",
        "    path = self.root_path + f\"/{self.task}/{self.view}/{index_extended}.npy\"\n",
        "    print(f'loading example: {index}')\n",
        "    x = np.load(path)\n",
        "    x = np.stack((x,)*self.n_channels, axis=1)\n",
        "    return x\n",
        "\n",
        "  def __load_features(self, index):\n",
        "    index_extended = '0' * (4 - len(str(index))) + str(index)\n",
        "    path = self.root_path + f\"/{self.task}/{self.view}/{self.extractor}/{index_extended}.npy\"\n",
        "    x = np.load(path).reshape((1, 512))\n",
        "    return x\n",
        "\n",
        "  def __load_labels(self):\n",
        "    records = pd.read_csv(self.root_path + f\"/{self.task}-{self.result_label}.csv\", header=None, names=['id', 'label'])\n",
        "    self.Y = records['label'].to_numpy()\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    'Generate one batch of data'\n",
        "    ind = self.indexes[index]\n",
        "    if self.X == None:\n",
        "      X = np.empty((self.batch_size, self.n_channels))\n",
        "      if self.extractor == None:\n",
        "        X = np.empty((self.batch_size, self.n_channels, *self.shape))\n",
        "      else:\n",
        "        X = np.empty((self.batch_size, self.shape))\n",
        "        #X = tf.squeeze(X)\n",
        "      #indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "      X = self.__load_scan(ind)\n",
        "    else:\n",
        "      X = self.X[ind]\n",
        "      \n",
        "    X = tf.expand_dims(X, 0)\n",
        "    Y = self.Y[ind:ind+1]\n",
        "\n",
        "  #  for i, ind in enumerate(indexes):\n",
        "  #    #indexes[i] = '0' * (4 - len(str(num))) + str(num)\n",
        "  #    if self.extractor == None:\n",
        "  #      #X[i,] = self.__load_scan(ind)\n",
        "  #      X = self.__load_scan(ind)\n",
        "  #      #X = applications.vgg16.preprocess_input(X)\n",
        "  #      X = tf.expand_dims(X, 0)\n",
        "        \n",
        "  #    else:\n",
        "  #      X[i,] = self.__load_features(ind)\n",
        "\n",
        "  #  Y = self.Y[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the number of batches per epoch'\n",
        "    return int(np.floor(self.num_examples / self.batch_size))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}