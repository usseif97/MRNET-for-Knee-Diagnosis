{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6O5TAVx2KIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications, layers, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "import keras.backend.tensorflow_backend as tfback\n",
        "import pandas as pd\n",
        "\n",
        "root_path = '/content/drive/My Drive/DataSet/MRNET data set/MRNet-v1.0'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPa6_1D9PlSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_example(root_path, task, view, model_name, num, features):\n",
        "  index = '0' * (4 - len(str(num))) + str(num)\n",
        "  print('saving example:', index)\n",
        "  np.save(open(f\"{root_path}/{task}/{view}/{model_name}/{index}.npy\", 'wb'), features)\n",
        "\n",
        "def load_labels(root_path, task, result_label):\n",
        "  records = pd.read_csv(root_path + f\"/{task}-{result_label}.csv\", header=None, names=['id', 'label'])\n",
        "  return records['label'].to_numpy()\n",
        "\n",
        "def load_features(root_path, task, view, model_name, start, end, dim):\n",
        "  features = np.empty((0, dim))\n",
        "  for i in range(start, end):\n",
        "    index = '0' * (4 - len(str(i))) + str(i)\n",
        "    path = root_path + f\"/{task}/{view}/{model_name}/{index}.npy\"\n",
        "    print('loading', index, 'features')\n",
        "    x = np.load(path).reshape((1, dim))\n",
        "    features = np.concatenate((features, x), axis = 0)\n",
        "  return features\n",
        "\n",
        "def plot_logs(logs, save_path):\n",
        "  fig = plt.figure(figsize=(20, 10))\n",
        "  plt.ylim(0, 1)\n",
        "  plt.plot(logs['loss'], 'g', label=\"train losses\")\n",
        "  plt.plot(logs['val_loss'], 'r', label=\"val losses\")\n",
        "  plt.grid(True)\n",
        "  plt.title('Training loss vs. Validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(save_path, bbox_inches='tight')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvG_ZnH8q2Jf",
        "colab_type": "text"
      },
      "source": [
        "Custom layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9cyGE2DDzUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Max(keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(Max, self).__init__(**kwargs)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    self.outputs = tf.math.reduce_max(\n",
        "        inputs, axis=0, keepdims=True\n",
        "    )\n",
        "    return self.outputs\n",
        "\n",
        "\n",
        "class Squeeze(keras.layers.Layer):\n",
        "  def __init__(self,**kwargs):\n",
        "    super(Squeeze, self).__init__(**kwargs)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    self.outputs = tf.squeeze(inputs, axis = 0)\n",
        "    return self.outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Luafloq5Za",
        "colab_type": "text"
      },
      "source": [
        "VGG16 from-scratch implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aGoVZMqqw_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for creating a vgg block\n",
        "def vgg_block(n_filters, n_conv):\n",
        "  # add convolutional layers \n",
        "  block = [layers.Conv2D(n_filters, (3,3), padding='same', activation='relu') for i in range(n_conv)]\n",
        "\t# add max pooling layer\n",
        "  block.append(layers.MaxPooling2D((2,2), strides=(2,2)))\n",
        "  return block\n",
        "\n",
        "def vgg_layers():\n",
        "  vgg_layers = vgg_block(64, 2)\n",
        "  vgg_layers.extend(vgg_block(128, 2))\n",
        "  vgg_layers.extend(vgg_block(256, 3))\n",
        "  vgg_layers.extend(vgg_block(512, 3))\n",
        "  vgg_layers.extend(vgg_block(512, 3))\n",
        "\n",
        "  return vgg_layers\n",
        "\n",
        "\n",
        "class VGG16():\n",
        "  def __init__(self, root_path, view, result_label, task = 'train'):\n",
        "    self.result_label = result_label\n",
        "    self.root_path = root_path\n",
        "    self.view = view\n",
        "    self.task = task\n",
        "    #Define The ConvNet: self.vgg_layers\n",
        "    self.vgg_layers = vgg_layers()\n",
        "\n",
        "    inputs = keras.Input(shape=(None, 3, 256, 256))\n",
        "    x = Squeeze()(inputs)\n",
        "    x = layers.experimental.preprocessing.Rescaling(scale=1.0 / 255)(x)\n",
        "    x = layers.experimental.preprocessing.RandomFlip(mode='horizontal')\n",
        "    for layer in self.vgg_layers:\n",
        "      x = layer(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = Max()(x)\n",
        "\n",
        "    outputs = layers.Dense(\n",
        "        1, activation='sigmoid', \n",
        "    )(x)\n",
        "\n",
        "    self.vgg_model = keras.Model(inputs, outputs)\n",
        "\n",
        "    self.vgg_model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-2), loss='binary_crossentropy', metrics=[keras.metrics.AUC()]\n",
        "        )\n",
        "    \n",
        "\n",
        "  def __save_history(self):\n",
        "    with open(self.root_path + f'/models/vgg16-scratch-{self.view}-{self.result_label}-history', 'wb') as file_pi:\n",
        "      pickle.dump(self.vgg_model_logs, file_pi)\n",
        "    \n",
        "  def __load_labels(self):\n",
        "    return load_labels(self.root_path, self.task, self.result_label)\n",
        "\n",
        "  def train_model(self, X = None, save_model = False):\n",
        "    self.task = 'train'\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "        min_delta=0,\n",
        "        patience=15,\n",
        "        verbose=0, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "    \n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto',\n",
        "      min_delta=0, cooldown=0, min_lr=1e-5\n",
        "    )\n",
        "    params = {'shape': (256, 256),\n",
        "        'n_channels': 3,\n",
        "        'batch_size': 1,\n",
        "        'shuffle': True,\n",
        "        'extractor': None,\n",
        "        'task': self.task, \n",
        "        'view': self.view, \n",
        "        'result_label': self.result_label\n",
        "    }\n",
        "\n",
        "    train_generator = MRNetDataGenerator(**params, bounds=(0, 1017), X = X)\n",
        "    valid_generator = MRNetDataGenerator(**params, bounds=(1017, 1130), X = X)\n",
        "    history = self.vgg_model.fit(\n",
        "        train_generator, batch_size=1, epochs=35, verbose=2, callbacks=[reduce_lr, early_stopping],\n",
        "        validation_data=valid_generator\n",
        "    )\n",
        "    self.vgg_model_logs = history.history\n",
        "    if save_model == True:\n",
        "      self.vgg_model.save(self.root_path + f'/models/vgg16-scratch-{self.view}-{self.result_label}.h5')\n",
        "      self.__save_history()\n",
        "\n",
        "    return self.vgg_model_logs\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pRl5t_2rb3a",
        "colab_type": "text"
      },
      "source": [
        "ResNet from-scratch implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xt8q0erUZaVC",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "  # defining name basis\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "  # Retrieve Filters\n",
        "  F1, F2, F3 = filters\n",
        "\n",
        "  # Save the input value. We'll need this later to add back to the main path. \n",
        "  X_shortcut = X\n",
        "\n",
        "  # First component of main path\n",
        "  X = layers.Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  # Second component of main path\n",
        "  X = layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = layers.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  # Third component of main path\n",
        "  X = layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = layers.BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "  # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "  X = layers.Add()([X, X_shortcut])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  return X\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "  # defining name basis\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "  # Retrieve Filters\n",
        "  F1, F2, F3 = filters\n",
        "    \n",
        "  # Save the input value\n",
        "  X_shortcut = X\n",
        "\n",
        "\n",
        "  ##### MAIN PATH #####\n",
        "  # First component of main path \n",
        "  X = layers.Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  # Second component of main path\n",
        "  X = layers.Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "  X = layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  # Third component of main path\n",
        "  X = layers.Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "  X = layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    \n",
        "  ##### SHORTCUT PATH ####\n",
        "  X_shortcut = layers.Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "  X_shortcut = layers.BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "  # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "  X = layers.Add()([X, X_shortcut])\n",
        "  X = layers.Activation('relu')(X)\n",
        "    \n",
        "  return X\n",
        "\n",
        "def ResNet50(X_input, classes = 1):   \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = layers.ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = layers.Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = layers.BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = layers.Activation('relu')(X)\n",
        "    X = layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "class ResNet():\n",
        "  def __init__(self, root_path, view, result_label, task = 'train'):\n",
        "    self.result_label = result_label\n",
        "    self.root_path = root_path\n",
        "    self.view = view\n",
        "    self.task = task\n",
        "\n",
        "    inputs = keras.Input(shape=(None, 3, 256, 256))\n",
        "    x = Squeeze()(inputs)\n",
        "    x = layers.experimental.preprocessing.Rescaling(scale=1.0 / 255)(x)\n",
        "    x = layers.experimental.preprocessing.RandomFlip(mode='horizontal')\n",
        "    x = ResNet50(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = Max()(x)\n",
        "\n",
        "    outputs = layers.Dense(\n",
        "        1, activation='sigmoid', \n",
        "    )(x)\n",
        "\n",
        "    self.resnet_model = keras.Model(inputs, outputs)\n",
        "\n",
        "    self.resnet_model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-2), loss='binary_crossentropy', metrics=[keras.metrics.AUC()]\n",
        "        )\n",
        "    \n",
        "    print(self.resnet_model.summary())\n",
        "\n",
        "  def __save_history(self):\n",
        "    with open(self.root_path + f'/models/resnet-scratch-{self.view}-{self.result_label}-history', 'wb') as file_pi:\n",
        "      pickle.dump(self.resnet_model_logs, file_pi)\n",
        "    \n",
        "  def __load_labels(self):\n",
        "    return load_labels(self.root_path, self.task, self.result_label)\n",
        "\n",
        "  def train_model(self, X = None, save_model = False):\n",
        "    self.task = 'train'\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "        min_delta=0,\n",
        "        patience=15,\n",
        "        verbose=0, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "    \n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto',\n",
        "      min_delta=0, cooldown=0, min_lr=1e-5\n",
        "    )\n",
        "    params = {'shape': (256, 256),\n",
        "        'n_channels': 3,\n",
        "        'batch_size': 1,\n",
        "        'shuffle': True,\n",
        "        'extractor': None,\n",
        "        'task': self.task, \n",
        "        'view': self.view, \n",
        "        'result_label': self.result_label\n",
        "    }\n",
        "\n",
        "    train_generator = MRNetDataGenerator(**params, bounds=(0, 1017), X = X)\n",
        "    valid_generator = MRNetDataGenerator(**params, bounds=(1017, 1130), X = X)\n",
        "    history = self.resnet_model.fit(\n",
        "        train_generator, batch_size=1, epochs=20, verbose=2, callbacks=[reduce_lr, early_stopping],\n",
        "        validation_data=valid_generator\n",
        "    )\n",
        "    self.resnet_model_logs = history.history\n",
        "    if save_model == True:\n",
        "      self.resnet_model.save(self.root_path + f'/models/resnet-scratch-{self.view}-{self.result_label}.h5')\n",
        "      self.__save_history()\n",
        "\n",
        "    return self.resnet_model_logs\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKiX5_nSrh-C",
        "colab_type": "text"
      },
      "source": [
        "Inception V3 from-scratch implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7z7cPxbQ1zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), name=None):\n",
        "    \"\"\"Utility function to apply conv + BatchNormalization.\n",
        "       BatchNormalization : Normalize the activations of the previous layer at each batch,\n",
        "        i.e. applies a transformation that maintains\n",
        "         the mean activation close to 0 and the activation standard deviation close to 1.\n",
        "    Arguments:\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        num_row: height of the convolution kernel.\n",
        "        num_col: width of the convolution kernel.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_conv'`\n",
        "            for the convolution and `name + '_bn'` for the\n",
        "            batch norm layer.\n",
        "    Returns:\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    if name is not None:\n",
        "        bn_name = name + '_bn'\n",
        "        conv_name = name + '_conv'\n",
        "    else:\n",
        "        bn_name = None\n",
        "        conv_name = None\n",
        "    '''\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        bn_axis = 1\n",
        "    else:\n",
        "        bn_axis = 3\n",
        "    '''\n",
        "    bn_axis = 1\n",
        "    x = layers.Conv2D(\n",
        "        filters, (num_row, num_col),\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        use_bias=False,\n",
        "        name=conv_name)(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
        "    x = layers.Activation('relu', name=name)(x)\n",
        "    return x\n",
        "\n",
        "def InceptionV3_from_scratch(input_layer):\n",
        "\n",
        "  #channel depth dimension\n",
        "  channel_axis = 1\n",
        "      \n",
        "  x = conv2d_bn(input_layer, 32, 3, 3, strides=(2, 2), padding='valid')\n",
        "  x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
        "  x = conv2d_bn(x, 64, 3, 3)\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  x = conv2d_bn(x, 80, 1, 1, padding='valid')\n",
        "  x = conv2d_bn(x, 192, 3, 3, padding='valid')\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  # mixed 0, 1, 2: 35 x 35 x 256\n",
        "  branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "  branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed0')\n",
        "  \n",
        "  # mixed 1: 35 x 35 x 256\n",
        "  branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "  branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed1')\n",
        "  # mixed 2: 35 x 35 x 256\n",
        "  branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "  branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed2')\n",
        "\n",
        "  # mixed 3: 17 x 17 x 768\n",
        "  branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "  branch3x3dbl = conv2d_bn(\n",
        "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "  x = layers.concatenate(\n",
        "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
        "\n",
        "  # mixed 4: 17 x 17 x 768\n",
        "  branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "  branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "  branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed4')\n",
        "\n",
        "  # mixed 5, 6: 17 x 17 x 768\n",
        "  for i in range(2):\n",
        "      branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "      branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
        "      branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
        "      branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "      branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
        "      branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "      branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
        "      branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "      branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "      branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "      branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "      x = layers.concatenate(\n",
        "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name='mixed' + str(5 + i))\n",
        "\n",
        "  # mixed 7: 17 x 17 x 768\n",
        "  branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "  branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "  branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "  x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed7')\n",
        "\n",
        "  # mixed 8: 8 x 8 x 1280\n",
        "  branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
        "  branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
        "                          strides=(2, 2), padding='valid')\n",
        "\n",
        "  branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
        "  branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
        "  branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
        "  branch7x7x3 = conv2d_bn(\n",
        "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "  x = layers.concatenate(\n",
        "        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name='mixed8')\n",
        "\n",
        "  # mixed 9: 8 x 8 x 2048\n",
        "  for i in range(2):\n",
        "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
        "\n",
        "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
        "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
        "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
        "        branch3x3 = layers.concatenate(\n",
        "            [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
        "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
        "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
        "        branch3x3dbl = layers.concatenate(\n",
        "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name='mixed' + str(9 + i))\n",
        "  \n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "class InceptionV3():\n",
        "  def __init__(self, root_path, view, result_label, task = 'train'):\n",
        "    self.result_label = result_label\n",
        "    self.root_path = root_path\n",
        "    self.view = view\n",
        "    self.task = task\n",
        "\n",
        "    inputs = keras.Input(shape=(None, 3, 256, 256))\n",
        "    x = Squeeze()(inputs)\n",
        "    x = layers.experimental.preprocessing.Rescaling(scale=1.0 / 255)(x)\n",
        "    x = layers.experimental.preprocessing.RandomFlip(mode='horizontal')\n",
        "    x = InceptionV3_from_scratch(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = Max()(x)\n",
        "\n",
        "    outputs = layers.Dense(\n",
        "        1, activation='sigmoid', \n",
        "    )(x)\n",
        "\n",
        "    self.inceptionv3_model = keras.Model(inputs, outputs)\n",
        "\n",
        "    self.inceptionv3_model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-2), loss='binary_crossentropy', metrics=[keras.metrics.AUC()]\n",
        "        )\n",
        "    \n",
        "    print(self.inceptionv3_model.summary())\n",
        "\n",
        "  def __save_history(self):\n",
        "    with open(self.root_path + f'/models/inceptionv3-scratch-{self.view}-{self.result_label}-history', 'wb') as file_pi:\n",
        "      pickle.dump(self.inceptionv3_model_logs, file_pi)\n",
        "    \n",
        "  def __load_labels(self):\n",
        "    return load_labels(self.root_path, self.task, self.result_label)\n",
        "\n",
        "  def train_model(self, X = None, save_model = False):\n",
        "    self.task = 'train'\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "        min_delta=0,\n",
        "        patience=15,\n",
        "        verbose=0, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "    \n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto',\n",
        "      min_delta=0, cooldown=0, min_lr=1e-5\n",
        "    )\n",
        "    params = {'shape': (256, 256),\n",
        "        'n_channels': 3,\n",
        "        'batch_size': 1,\n",
        "        'shuffle': True,\n",
        "        'extractor': None,\n",
        "        'task': self.task, \n",
        "        'view': self.view, \n",
        "        'result_label': self.result_label\n",
        "    }\n",
        "\n",
        "    train_generator = MRNetDataGenerator(**params, bounds=(0, 1017), X = X)\n",
        "    valid_generator = MRNetDataGenerator(**params, bounds=(1017, 1130), X = X)\n",
        "    history = self.inceptionv3_model.fit(\n",
        "        train_generator, batch_size=1, epochs=20, verbose=2, callbacks=[reduce_lr, early_stopping],\n",
        "        validation_data=valid_generator\n",
        "    )\n",
        "    self.inceptionv3_model_logs = history.history\n",
        "    if save_model == True:\n",
        "      self.inceptionv3_model.save(self.root_path + f'/models/inceptionv3-scratch-{self.view}-{self.result_label}.h5')\n",
        "      self.__save_history()\n",
        "\n",
        "    return self.inceptionv3_model_logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9nsKa_8roUi",
        "colab_type": "text"
      },
      "source": [
        "TransferLearning Class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gPG5Y84DPmPH",
        "colab": {}
      },
      "source": [
        "\"\"\"Transfer Learning\"\"\"\n",
        "class TransferLearningModel():\n",
        "  def __init__(self, root_path, view, result_label, model_name, task = 'train'):\n",
        "    self.result_label = result_label\n",
        "    self.root_path = root_path\n",
        "    self.view = view\n",
        "    self.task = task\n",
        "    self.model_name = model_name\n",
        "    #Define The ConvNet: self.cnn_layer\n",
        "    if self.model_name == 'vgg16':\n",
        "      self.cnn_layer = applications.VGG16(\n",
        "          include_top=False,\n",
        "          weights=\"imagenet\",\n",
        "          input_shape=(3, 256,256),\n",
        "          pooling='avg'\n",
        "      )\n",
        "      self.output_dim = 512\n",
        "    elif self.model_name == 'resnet':\n",
        "      self.cnn_layer = keras.applications.ResNet50(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=(3,256,256),\n",
        "        pooling='avg',\n",
        "      )\n",
        "      self.output_dim = 2048\n",
        "    elif self.model_name == 'inceptionv3':\n",
        "      self.cnn_layer = keras.applications.InceptionV3(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=(3,256,256),\n",
        "        pooling='avg',\n",
        "      )\n",
        "      self.output_dim = 2048\n",
        "    self.cnn_layer.trainable = False\n",
        "\n",
        "    #Define the input layer + the convnet + the maxpool layer \n",
        "    #   : self.extractor\n",
        "    inputs = keras.Input(shape=(None, 3, 256, 256))\n",
        "    x = Squeeze()(inputs)\n",
        "    if model_name == 'vgg16':\n",
        "      x = applications.vgg16.preprocess_input(x)\n",
        "    elif model_name == 'resnet':\n",
        "      x = applications.resnet.preprocess_input(x)\n",
        "    elif model_name == 'inceptionv3':\n",
        "      x = applications.inception_v3.preprocess_input(x)\n",
        "\n",
        "    x = self.cnn_layer(x, training=False)\n",
        "    outputs = Max()(x)\n",
        "    self.extractor = keras.Model(inputs, outputs)\n",
        "    self.extractor.compile()\n",
        "\n",
        "    #Define the FC layer: self.fc\n",
        "    inputs = keras.Input(shape=(self.output_dim,))\n",
        "    outputs = layers.Dense(\n",
        "        1, activation='sigmoid', \n",
        "        kernel_regularizer=keras.regularizers.l2(0.1), \n",
        "        bias_regularizer=keras.regularizers.l2(0.1)\n",
        "    )(inputs)\n",
        "    self.fc = keras.Model(inputs, outputs)\n",
        "\n",
        "  def __save_example(self, num, features):\n",
        "    save_example(self.root_path, self.task, self.view,self.model_name , num, features)\n",
        "\n",
        "  def __load_labels(self):\n",
        "    return load_labels(self.root_path, self.task, self.result_label)\n",
        "\n",
        "\n",
        "\n",
        "  def __load_features(self):\n",
        "    if self.task == 'train':\n",
        "      start = 0\n",
        "      end = 1130\n",
        "    else:\n",
        "      start = 1130\n",
        "      end = 1250\n",
        "    \n",
        "    self.features = load_features(self.root_path, self.task, self.view,\n",
        "                                   self.model_name, start, end, self.output_dim)\n",
        "    return self.features\n",
        "  \n",
        "  def __save_history(self):\n",
        "    with open(self.root_path + f'/models/{self.model_name}-auc-fc-{self.view}-{self.result_label}-history', 'wb') as file_pi:\n",
        "      pickle.dump(self.train_fc_logs, file_pi)\n",
        "\n",
        "  def plot_logs(self):\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    plt.ylim(0, 1)\n",
        "    plt.plot(self.train_fc_logs['loss'], 'g', label=\"train losses\")\n",
        "    plt.plot(self.train_fc_logs['val_loss'], 'r', label=\"val losses\")\n",
        "    plt.grid(True)\n",
        "    plt.title('Training loss vs. Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(self.root_path + f'/figures/{self.model_name}-{self.view}-{self.result_label}.png', bbox_inches='tight')\n",
        "\n",
        "\n",
        "  def __load_history(self):\n",
        "    return pickle.load(open(self.root_path + f'/models/{self.model_name}-auc-fc-{self.view}-{self.result_label}-history', 'rb'))\n",
        "\n",
        "  def load_fc(self):\n",
        "    self.fc = keras.models.load_model(\n",
        "      self.root_path + f'/models/{self.model_name}-auc-fc-{self.view}-{self.result_label}.h5', compile=True\n",
        "      )\n",
        "    self.train_fc_logs = self.__load_history()\n",
        "\n",
        "  def extract_features(self, task, save = False, X = None):\n",
        "    self.task = task\n",
        "    self.features = np.empty((0,512))\n",
        "    if X != None:\n",
        "      for i in range(1130):\n",
        "        print(f'extracting {i} (Memory Mode)')\n",
        "        x = X[i]\n",
        "        x = tf.expand_dims(x, 0)\n",
        "        Y = self.extractor.predict(\n",
        "          x, batch_size=1, verbose=0\n",
        "        )\n",
        "        self.features = np.concatenate((self.features,Y) , axis = 0)\n",
        "    else:\n",
        "      params = {'shape': (256, 256),\n",
        "          'n_channels': 3,\n",
        "          'batch_size': 1,\n",
        "          'shuffle': False,\n",
        "          'extractor': None,\n",
        "          'task': self.task, \n",
        "          'view': self.view, \n",
        "          'result_label': self.result_label}\n",
        "\n",
        "      predict_generator = MRNetDataGenerator(**params)\n",
        "      self.features = self.extractor.predict(\n",
        "        predict_generator, verbose=0\n",
        "      )\n",
        "\n",
        "    if save == True:\n",
        "      shift = 0\n",
        "      if self.task == 'valid':\n",
        "        shift = 1130\n",
        "      for example_num, example_features in enumerate(self.features):\n",
        "        self.__save_example(example_num + shift, example_features)\n",
        "\n",
        "    return self.features\n",
        "\n",
        "  def predict_fc(self):\n",
        "    self.load_fc()\n",
        "    X = self.__load_features()\n",
        "    self.predictions = self.fc.predict(\n",
        "      X, verbose=1\n",
        "    )\n",
        "    return self.predictions\n",
        "\n",
        "\n",
        "  def train_fc(self, memory = False, save_fc = False):\n",
        "    self.task = 'train'\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "        min_delta=0,\n",
        "        patience=5,\n",
        "        verbose=0, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "    \n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='val_loss', factor=0.1, patience=3, verbose=0, mode='auto',\n",
        "      min_delta=0, cooldown=0, min_lr=1e-5\n",
        "    )\n",
        "    \n",
        "    if memory == True:\n",
        "      Y = self.__load_labels()\n",
        "      X = self.__load_features()\n",
        "      self.fc.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=[keras.metrics.AUC()]\n",
        "      )\n",
        "      history = self.fc.fit(\n",
        "          x=X, y=Y, batch_size=1, epochs=35, verbose=2, callbacks=[reduce_lr, early_stopping],\n",
        "          validation_split=0.1, validation_data=None, shuffle=True,\n",
        "      )\n",
        "      self.train_fc_logs = history.history\n",
        "\n",
        "    else:\n",
        "      pass\n",
        "    if save_fc == True:\n",
        "      self.fc.save(self.root_path + f'/models/{self.model_name}-auc-fc-{self.view}-{self.result_label}.h5')\n",
        "      self.__save_history()\n",
        "\n",
        "    return self.train_fc_logs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='val_loss', factor=0.5, patience=5, verbose=0, mode='auto',\n",
        "      min_delta=0, cooldown=0, min_lr=1e-7\n",
        "    )\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUCIVWmlh1n8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}